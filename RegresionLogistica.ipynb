{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  1.],\n",
       "       [ 2.,  1.],\n",
       "       [ 2.,  1.],\n",
       "       ..., \n",
       "       [ 2.,  0.],\n",
       "       [ 2.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "from datos import Datos\n",
    "from estrategiasparticionado.validacion_cruzada import ValidacionCruzada\n",
    "from estrategiasparticionado.validacion_simple import ValidacionSimple\n",
    "from clasificadores.clasificador_regresion_logistica import ClasificadorRegresionLogistica\n",
    "\n",
    "dataset=Datos('./conjunto_datos/tic-tac-toe.data')\n",
    "dataset2=Datos('./conjunto_datos/german.data')\n",
    "dataset.datos[:,[1, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160 793 164 407 576 528 533 729 743 266 139 222 210 168 480 607 860 184\n",
      "  98 940 687 415 644 536 197 220 581 598 741 232 511 610 601 482 308 557\n",
      " 358 373 926 290 946 947 101 493 643   8 127 224 490  57 417 441 428 622\n",
      " 297 611 488 586 479 506 705 750  67 951 234 484 762 522 540 749 792 142\n",
      " 572 596  84 271 303 386 250 474 270 362 174 870 852 466 219 825 273 578\n",
      " 872 269 173  59 113 406 316 939 381 910 150 890 130  19 354 537 803 887\n",
      "  54 446 626 247 854 788  87 915 399 943 595 831 145 695 470 696 547 363\n",
      " 670 571 242 606 846 843 367  62 667 787 864 862 328 228 662 721 632 293\n",
      " 318 615 126 380 332 252  20 764  51 162 646 855 514 842 409 396 885 256\n",
      " 888  94 509 613 356 945 410 661 258 579 801 853 710 932 421 461 398   3\n",
      "  75 840 212 790 920  39  31 353 238 655  82  43 746  16 566 330 573 678\n",
      " 765 737 914 554 806 758  63 556 405  79 154  21 239  77 954 612 577 923\n",
      "   4 382 756 350 829 481 889 836 371 458 805 942 519 543  18  92 633  81\n",
      " 117 804 345 209 798  11 169 422 134 340 352 724 819 895 369 229 515 699\n",
      " 254 631 755  76 455 190  17 652  13 395 211 627 660 158   1 218  47 304\n",
      " 502 447 434 645 897  27 281 779 810 751 206 638 504 815 525 589 813 861\n",
      " 157 299 426 742 549 569 495 551 175 651  66 214 226 713 327 433   0  50\n",
      " 609 816 180 564 372 620 608  71 411 529 740 223 933 505  29 726 459 672\n",
      " 205 558 468 704 574 408 339 188 448 774 120 131 901  38 323 953 648 684\n",
      " 621 178  28 663 507 151 818 294 346 681 217 553 207 592 941  40 714 141\n",
      " 383  35 624 845 351 689 881 617 614  74 822 170 899 203 871 783 693 849\n",
      " 634 298 272 938 116 761 763 623 675 880 735 688 321 277 906 257 937 122\n",
      " 664 379 200 194  36 260 692 830 244 233 701 597 538 172 245 944  95 378\n",
      " 414 874 800 530 431 337 167 896 834 462 166 809 404 295  58 918 146  99\n",
      " 315 496 903 133 300 341 280 824 268 237 747  14 329 796 640 917  55 498\n",
      " 856 336 177 112 201 919 682 494 261 384 752  64 588 832 289 745 512 193\n",
      " 333  32 785 857 105 508 791  48 738 251 867 445 432 956 795 143 593 891\n",
      " 649 619 359 309 489 181 921 585   2 100 952 235  89 418 292 876 548 775\n",
      " 460  46 732 772 698 165  52 602 135 545 676 286 769 478 767  69 541  26\n",
      " 123 368 568 390 375 927 296 863 236  30 757 827 520 161 707 195 625 147\n",
      " 185 650  93 686 886 550 916 317 176 119 719 111 934 659 338 182   5  53\n",
      " 636  44 877 555  15 838 753 616 928 400 171 420  45 424 789 187 291 467\n",
      " 544 263 302 630 152 138 311 778 531 385 225 931 456 878 285 513 823 325\n",
      " 552 387 444 728  61 924 902 905 582 216 221 499 717 124 413  10 148 727\n",
      "  72  37 129 812 189  33 590 570 227 437 708 438 391 487 457 858 274  25\n",
      " 436 389 794 780 702 439 288 839 198 603 948 546 114 393 559 284 534 322\n",
      " 802 423 900 847 149 639 814 784 186 243 580 503 848 936 115 249 628 403\n",
      " 706 477 313  90]\n",
      "[930 255 110 275 331 567 532 653 183 159 723 483  34 246 833 344 517  70\n",
      " 565 524 442 279 241 722 700 808 419 807 935 841 132 276 106 882 155 473\n",
      " 430 527 485 629 253 697 370 440 305 128 665 539 575  97 711 196 388 510\n",
      " 449 739 691 355 583 427 402 561 913 401 265 464  12   9 911 320 949 894\n",
      " 703 240  91 500 491 782 690 865 376 594 869 777  56 658 443 278 754 144\n",
      " 925 475 108 486 656 312 472  86 377 587 731 715 654 844 314 248 909 450\n",
      " 642 734  68 811 677 759 776  42  85 680 730 560 875 191 334 454 463 267\n",
      " 156 760  65 884 859 673 435 394 771 153 365 535 679   7 192  22 453  60\n",
      " 425 342 202 125 618 851 866 605  78 828 471 591 518 685 310  80 452 326\n",
      " 497 912 492 893 282 526 501 208 770 523 259 826 898 766 908 768 674 179\n",
      " 657 199 109  83 349 666 103 733 416  24 671 361 429 366 709 797 163 892\n",
      " 306 324 647 121 516 107  49 140 820 599 307 718 213 451 335  73 744 136\n",
      " 720 781 563 343 412 137 469 817 922 821 850 600 231 929 204 669 955 562\n",
      " 360 883 950  88 837 374 584 668 712   6 319 465 104 364 957 694  23 641\n",
      " 835 868 521 736 873 262 287  41 230 102 637 904 635 264 348 476 716 879\n",
      " 397  96 773 392 604 786 799 347 118 215 357 725 683 907 301 542 748 283]\n"
     ]
    }
   ],
   "source": [
    "validacionSimple = ValidacionSimple()\n",
    "validacionSimple.creaParticiones(dataset.datos)\n",
    "for particion in validacionSimple.particiones:\n",
    "    print(particion.indicesTrain)\n",
    "    print(particion.indicesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([675,  63, 793, 784, 479, 421, 805, 697, 589, 489, 236, 401, 679,\n",
       "        92, 726,  21, 671, 916, 633, 676, 621, 611, 268, 148,  29, 398,\n",
       "       847, 496, 334,  27, 745, 630, 513, 230, 946, 315, 337, 739, 463,\n",
       "       218, 439, 436, 183, 771, 772,   7, 209, 617, 759,  98, 600, 535,\n",
       "       330, 750, 880, 729, 667, 448, 547, 728, 647, 866, 906, 267, 879,\n",
       "       457, 944, 546, 114, 766, 615, 458, 287, 161, 144, 181, 720, 215,\n",
       "       187, 949, 932, 178,  47, 523, 923, 818, 785,  57, 735, 185, 929,\n",
       "       953, 593, 111, 791, 443, 814, 672, 690, 563, 353, 905, 886, 235,\n",
       "        36, 635, 255,  72, 332, 397, 557, 740, 309, 639, 290, 532, 687,\n",
       "        35, 302,  44, 915, 262,  60, 478, 518, 388, 500, 134, 298, 582,\n",
       "       297, 590, 263, 749, 554, 734, 455, 762, 670, 460, 503, 855,  13,\n",
       "       336,  46, 763,  23, 912, 429, 891, 789, 701, 414, 412,  88, 601,\n",
       "       832, 662, 157, 760, 603, 952, 419, 862, 924, 779, 664, 495, 394,\n",
       "       951, 411, 790,   0,  80, 591, 207, 350, 122, 831, 437, 654, 188,\n",
       "       692, 893, 498, 507, 126, 408, 219, 640, 836, 233, 203, 922, 695,\n",
       "       480, 939, 875, 595, 228,  71, 238, 848, 770, 851, 883, 826, 820,\n",
       "        25, 395, 403, 856, 504, 132, 809, 482, 318, 706, 402, 700, 910,\n",
       "       270, 151, 325, 440, 102, 285, 607, 824, 150, 686, 305, 182, 608,\n",
       "       669, 817, 588,  50, 699, 348, 127, 928, 314, 141, 339, 908, 788,\n",
       "       666,  45, 226, 542, 577, 804, 898, 327, 957, 138, 516, 137, 510,\n",
       "       798, 765, 445, 261, 175, 919, 622, 342, 571, 358, 713, 288, 422,\n",
       "       548, 371, 299, 400, 684, 180, 823, 573, 167, 258, 308, 430, 274,\n",
       "       282, 598,  93, 286,  99, 364,  68, 300, 232, 435, 718, 272, 878,\n",
       "       427, 795, 418, 359, 220, 506, 462, 894, 786, 159, 553,  90, 275,\n",
       "         5, 390,  66, 165, 746, 581, 174, 259, 333, 560, 432, 541, 732,\n",
       "       195,  33, 815, 273, 846, 310, 213, 121, 748, 808, 660, 377, 338,\n",
       "       522,  24, 499, 424, 704, 624, 153, 807, 605, 389, 202, 743, 931,\n",
       "       293, 787, 248, 385, 933, 612,  85, 152, 555, 212, 721, 892,  64,\n",
       "       936, 378, 501, 874, 467, 673, 396, 544, 597, 386, 295, 269, 113,\n",
       "       895, 283,  75, 340, 920, 756, 849,   2, 940, 208, 737, 294, 229,\n",
       "       475, 899, 505,  43, 942, 271, 279, 116, 568, 865, 372, 947, 512,\n",
       "       863,  12, 585, 313, 651, 384, 583, 198, 872, 103, 869,  96,  31,\n",
       "       689,  82, 240, 564, 347,  40, 368, 492, 559,  53, 449, 160, 828,\n",
       "       465, 461, 331, 276,   4, 514, 543, 434, 162, 629, 714, 454, 768,\n",
       "       438, 678, 140, 265, 156, 502, 428, 576, 712, 135,  15, 125, 859,\n",
       "       867, 253, 456, 361, 921, 606, 708, 155, 711, 950, 930, 903, 301,\n",
       "       356,  41, 913, 326, 374, 741,   8, 753, 782, 307, 206,  52, 352,\n",
       "       444, 584, 757, 145, 494, 158, 616, 955, 777, 139, 488, 550, 222,\n",
       "       868, 696, 129, 864, 842, 566, 447, 858, 659, 453, 485, 890, 705,\n",
       "       363, 625, 147, 945, 937, 375, 956, 477, 918,  69, 592, 266,  18,\n",
       "       486,  20,  26, 643, 320,   9, 529, 289, 149,  58, 101, 902, 468,\n",
       "       602, 538,  74, 558, 709, 904,  79, 885, 613, 241, 715, 487,   3,\n",
       "       196, 154, 214, 730, 707, 193, 631, 171, 646, 168, 812, 850, 716,\n",
       "       100, 404, 806, 303, 882, 813, 665, 800,  65, 827, 628, 769, 870,\n",
       "       472,  67, 120, 767, 887,  55, 413, 873, 618, 362, 382,  54, 636,\n",
       "       531, 335,  78, 764, 441, 433,  91, 177, 811, 291, 376, 508, 216,\n",
       "       599, 280, 799, 524, 321, 742, 344, 243, 594, 383, 948, 845, 776,\n",
       "       642, 632, 420, 470, 211, 247, 446, 717, 517, 838, 822, 614, 844,\n",
       "       351, 511, 346, 604, 476, 907, 118,  19, 108, 810, 106, 792, 387,\n",
       "       328, 578, 674, 256, 373, 131,  97, 561,  59, 653, 658, 691, 693,\n",
       "       530, 710, 755, 528, 837, 366, 652, 169, 901, 738, 416,   1, 329,\n",
       "       244, 515, 260,  56, 367, 747, 204, 794, 474,  38,  22, 724,  61,\n",
       "       163, 567, 399, 451, 619, 775,  84, 281,  37,  81, 537, 277, 698,\n",
       "       572, 774, 231, 527, 172, 694, 884, 257,  32, 569, 173, 638, 481,\n",
       "       927, 610, 725, 406, 552, 415, 410, 360, 661, 860, 702, 370, 650,\n",
       "       911, 192,  89, 369, 509,  34, 452, 381,  51, 237, 186, 637, 124,\n",
       "       881, 107, 852, 533, 190, 934, 250, 497, 854,  86, 323, 254, 751,\n",
       "       392,  73, 324, 733, 889, 574, 306,  62, 426, 249,  94, 778, 224,\n",
       "       142, 545, 900, 380, 897, 703, 861, 736, 648, 663, 365, 189, 319,\n",
       "       816, 943, 170, 871, 194, 252, 345,  17, 473, 909, 442, 355, 405,\n",
       "       304,  42, 644, 761, 197, 225, 459, 954, 110, 853, 857,  10, 797,\n",
       "       115,  48, 379, 634, 938, 723, 796, 278, 354, 681, 677, 562, 579,\n",
       "        16, 246, 393, 682, 688, 245, 104, 464, 549,  30, 680, 264, 839,\n",
       "       484, 645, 539, 627, 835, 217, 575, 357, 876, 123, 471, 935, 343,\n",
       "       727, 491, 199,  87, 292, 752,  49, 431, 620, 877,  70, 719, 105,\n",
       "       896, 483, 526,  28, 191, 801, 391, 133, 425, 520, 888, 490, 925,\n",
       "       596, 781, 534, 825])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validacionCruzada = ValidacionCruzada()\n",
    "\n",
    "validacionCruzada.creaParticiones(dataset.datos)\n",
    "\n",
    "    \n",
    "validacionCruzada.particiones[0].indicesTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  2.,  2.,  2.,  1.,  1.,  2.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.extraeDatosTrain(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.91006909  0.72175543  0.96506334  0.61912121  0.88607877  0.96546911\n",
      "  0.99137923  0.99052073  0.89897617  0.92890383  0.97119399  0.95761212\n",
      "  0.55731218  0.73797783  0.79324704  0.79084656  0.87845303  0.83176245\n",
      "  0.97379857  0.96663746  0.96622673  0.87204193  0.99285291  0.95330974\n",
      "  0.74952615  0.89887716  0.961953    0.95976109  0.99232312  0.95312598\n",
      "  0.90394738  0.95808528  0.98309132  0.94581688  0.67888984  0.80705688\n",
      "  0.71487928  0.9361124   0.9461812   0.98572635  0.89723833  0.73348426\n",
      "  0.93020433  0.95127447  0.34293448  0.97687942  0.95387174  0.97286795\n",
      "  0.95497527  0.92603674  0.32725192  0.92422138  0.94455461  0.97775275\n",
      "  0.82986607  0.42005174  0.8142571   0.7981274   0.99108558  0.64582206\n",
      "  0.93093464  0.98027645  0.94735453  0.90749866  0.92220613  0.93227497\n",
      "  0.62195385  0.85855475  0.88908573  0.91734572  0.93552414  0.85302583\n",
      "  0.98723611  0.72870543  0.93125223  0.95701467  0.86256508  0.36168835\n",
      "  0.92837647  0.94253167  0.92812107  0.86452883  0.94100428  0.98914644\n",
      "  0.95728942  0.69294496  0.98656578  0.99586837  0.97970293  0.80051848\n",
      "  0.94281318  0.93730947  0.54761668  0.9815882   0.80251911  0.95932983\n",
      "  0.86509014  0.98701188  0.86137847  0.51447423  0.89124989  0.89238762\n",
      "  0.9783903   0.95312047  0.78978542  0.95851007  0.64619825  0.73950216\n",
      "  0.96825862  0.9912595   0.98538023  0.98805902  0.51892131  0.77292738\n",
      "  0.46757746  0.9082401   0.95350981  0.8670507   0.86883596  0.96099825\n",
      "  0.92857839  0.93739481  0.57591265  0.55399438  0.98494834  0.97908234\n",
      "  0.97125338  0.92583272  0.97654893  0.86219738  0.70716009  0.94174137\n",
      "  0.54223402  0.9056293   0.95486527  0.82082175  0.69603721  0.99097698\n",
      "  0.98461395  0.49315881  0.94708443  0.96178781  0.99437376  0.96739377\n",
      "  0.85612358  0.93165887  0.61215718  0.90395259  0.97421234  0.95522771\n",
      "  0.99315275  0.8952209   0.79043349  0.91154881  0.98238285  0.8699944\n",
      "  0.92879882  0.85545683  0.77443578  0.98619     0.72270654  0.82252386\n",
      "  0.87741197  0.71142157  0.96524508  0.96859344  0.79134792  0.83906881\n",
      "  0.95569043  0.41263533  0.86578371  0.8961571   0.98556802  0.90647679\n",
      "  0.97930867  0.96688729  0.95513398  0.97156222  0.99206559  0.9196658\n",
      "  0.95671672  0.95338042  0.91002605  0.9351389   0.93965708  0.99545647\n",
      "  0.77104341  0.99473895  0.95556921  0.99194906  0.99628397  0.94796687\n",
      "  0.87216347  0.94299329  0.43091096  0.97804434  0.96589821  0.96242262\n",
      "  0.6299234   0.95827242  0.7592484   0.70439464  0.79006127  0.98293759\n",
      "  0.88741059  0.92678772  0.8341283   0.99247308  0.98780285  0.85263697\n",
      "  0.98406694  0.73386685  0.97892863  0.94506823  0.95266691  0.94389833\n",
      "  0.90509268  0.90010119  0.99592791  0.81180011  0.99524524  0.89023349\n",
      "  0.92625753  0.99564389  0.70984595  0.99501345  0.97926704  0.89787051\n",
      "  0.89971892  0.99238538  0.97434949  0.91948916  0.97468905  0.38975341\n",
      "  0.88125488  0.9825741   0.97749866  0.84301504  0.94935447  0.90122097\n",
      "  0.90357246  0.91628328  0.90701823  0.8632275   0.91552458  0.90719058\n",
      "  0.96280457  0.87921562  0.98331568  0.54472344  0.67500852  0.98956185\n",
      "  0.9392459   0.91861632  0.99168296  0.6090831   0.87636295  0.64653719\n",
      "  0.77524649  0.97710496  0.97696204  0.91245595  0.98570318  0.96551602\n",
      "  0.97417098  0.85989857  0.94104072  0.9868007   0.81697285  0.84044187\n",
      "  0.915825    0.96697286  0.86023599  0.87145167  0.88018296  0.55315137\n",
      "  0.98925544  0.88700186  0.65123972  0.95786023  0.9434098   0.70146318\n",
      "  0.85589985  0.81675545  0.94856893  0.73219988  0.71143261  0.99484196\n",
      "  0.9834983   0.99796992  0.86759653  0.88624473  0.99440928  0.95858554\n",
      "  0.97339671  0.7598348   0.98047277  0.75593129  0.80742599  0.97243277\n",
      "  0.83893529  0.83051706  0.74324569  0.86001761  0.98482965  0.97811077\n",
      "  0.97571223  0.92501915  0.99147943  0.98713971  0.98666844  0.48046112\n",
      "  0.74520195  0.68525741  0.99636856  0.80075244  0.95779848  0.97519395\n",
      "  0.54644614  0.97030126  0.64633555  0.54636377  0.96953698  0.33965801\n",
      "  0.83376252  0.82604718  0.91449327  0.75433431  0.96923712  0.8187296\n",
      "  0.9817194   0.98365769  0.90842708  0.99039147  0.97978399  0.56990205\n",
      "  0.93607648  0.99068495  0.97052486  0.72613071  0.96812351  0.76597116\n",
      "  0.88533011  0.64363528  0.62423894  0.85609975  0.79847105  0.97537757\n",
      "  0.95465546  0.98260129  0.76646104  0.88205995  0.95210787  0.98146927\n",
      "  0.84437031  0.99012351  0.94790589  0.90879184  0.59577342  0.91882149\n",
      "  0.29114898  0.98220539  0.98114123  0.98682432  0.47022887  0.99641269\n",
      "  0.89164958  0.93485074  0.98734421  0.96924995  0.87290177  0.8890802\n",
      "  0.97195633  0.86853625  0.96982324  0.64822167  0.97390664  0.79410173\n",
      "  0.44796434  0.65987391  0.96334149  0.86551454  0.66216027  0.95765823\n",
      "  0.95680739  0.99083456  0.93871275  0.78150543  0.92376961  0.64043655\n",
      "  0.99111443  0.8040661   0.96605595  0.89717777  0.97813292  0.81455564\n",
      "  0.99474016  0.89196718  0.84497772  0.62756877  0.41466895  0.80312613\n",
      "  0.57795691  0.98019176  0.95857613  0.84946109  0.68976416  0.60082541\n",
      "  0.93937601  0.98333188  0.9195811   0.43793001  0.90139514  0.99243336\n",
      "  0.86814692  0.77990277  0.97627479  0.96366794  0.98817378  0.95326553\n",
      "  0.68554418  0.99025219  0.70504261  0.47771374  0.99338158  0.96075154\n",
      "  0.93145407  0.63384255  0.98748833  0.58150781  0.95534423  0.59896307\n",
      "  0.81887429  0.95166868  0.65588801  0.99682823  0.93486518  0.91214916\n",
      "  0.88911297  0.85343543  0.93931125  0.94398538  0.74236348  0.93775234\n",
      "  0.84022115  0.90221931  0.74383649  0.91350951  0.95854715  0.97979699\n",
      "  0.97004994  0.9644042   0.92155702  0.99292123  0.96220868  0.60167517\n",
      "  0.94075469  0.99596816  0.9129554   0.95035467  0.72568391  0.9859429\n",
      "  0.86662346  0.98815732  0.95570705  0.81704598  0.77740821  0.95011191\n",
      "  0.70204729  0.92592399  0.76598168  0.94541706  0.9874094   0.70748905\n",
      "  0.94141131  0.77815324  0.89567026  0.35215947  0.31681009  0.97168804\n",
      "  0.37680607  0.94101743  0.92556511  0.98794225  0.97859115  0.89384593\n",
      "  0.99600682  0.77936077  0.98778324  0.90136732  0.91112166  0.97512366\n",
      "  0.97786017  0.98521626  0.83361003  0.77502988  0.64797374  0.49939013\n",
      "  0.88982923  0.81826933  0.88480927  0.73380572  0.96301741  0.77168598\n",
      "  0.95550754  0.70774822  0.8339549   0.4781242   0.92073599  0.90727377\n",
      "  0.83583163  0.77544607  0.93399791  0.98227066  0.87461227  0.63563149\n",
      "  0.97942431  0.90800802  0.47198433  0.97856569  0.98483608  0.96172802\n",
      "  0.990922    0.92710876  0.97401024  0.98949387  0.9677424   0.98571243\n",
      "  0.96221316  0.92925215  0.98566548  0.78282096  0.85154119  0.97418749\n",
      "  0.91420812  0.91124993  0.55747417  0.99015545  0.99371692  0.91652064\n",
      "  0.9379704   0.97654237  0.82300364  0.80338611  0.54191879  0.86677513\n",
      "  0.82789962  0.97581559  0.76617649  0.94907973  0.95073676  0.75923742\n",
      "  0.96085777  0.51898303  0.95923654  0.98293361  0.81013328  0.9767389\n",
      "  0.95135067  0.71751118  0.73479222  0.41125215  0.69709258  0.84921895\n",
      "  0.98955947  0.97567029  0.80907083  0.91859492  0.78043414  0.93137648\n",
      "  0.8132007   0.91665     0.87295506  0.96123973  0.85194957  0.53283852\n",
      "  0.95746626  0.6821186   0.80152355  0.97198564  0.98269143  0.9794392\n",
      "  0.82468945  0.99075756  0.86299616  0.98667156  0.97471617  0.90455419\n",
      "  0.99074355  0.78098781  0.8967013   0.7781636   0.97223312  0.88873535\n",
      "  0.8525755   0.9567994   0.92920819  0.54392128  0.71678348  0.92605818\n",
      "  0.72678067  0.94943082  0.94328001  0.91933982  0.94609737  0.93114684\n",
      "  0.98879625  0.66654143  0.37338989  0.9617791   0.99263794  0.96881259\n",
      "  0.93382834  0.57267048  0.82419572  0.7794925   0.79327494  0.31936801\n",
      "  0.89761431  0.98509447  0.76934412  0.92456288  0.94404351  0.63447937\n",
      "  0.82086778  0.63411078  0.88839102  0.88825621  0.94370202  0.24221402\n",
      "  0.97995392  0.50189268  0.99322789  0.88034171  0.97590592  0.80258711\n",
      "  0.99376313  0.96834768  0.93148155  0.64312004  0.98600845  0.95998367\n",
      "  0.866102    0.95579147  0.14114563  0.9641437   0.98755369  0.94394309\n",
      "  0.98905667  0.90353494  0.98326718  0.97961836  0.50511563  0.90790079\n",
      "  0.90089635  0.89853155  0.44544241  0.85680329  0.46659987  0.94788567\n",
      "  0.83517196  0.92624091  0.69287425  0.89442615  0.99469705  0.94255385\n",
      "  0.93672817  0.86908332  0.93185946  0.71177022]\n",
      "[array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,\n",
      "        1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.])]\n"
     ]
    }
   ],
   "source": [
    "clasificador = ClasificadorRegresionLogistica()\n",
    "res = clasificador.validacion(validacionSimple, dataset)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ClasificadorRegresionLogistica' object has no attribute 'prioris'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f8fb4cee8a57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclasificador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprioris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ClasificadorRegresionLogistica' object has no attribute 'prioris'"
     ]
    }
   ],
   "source": [
    "hist = np.histogram([1, 2, 3,2],bins=len(np.unique([1, 2, 3, 3])))\n",
    "clasificador.prioris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = np.array([[1, 0, 1],[1, 0, 0],[1, 0, 1]])\n",
    "matrix[np.where(matrix[-1] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.582053    0.58691997  0.57201855  0.65323734  0.5952221   0.60421096\n",
      "  0.58547062  0.57845826  0.58277962  0.58988392  0.61298794  0.50099575\n",
      "  0.50727777  0.59173041  0.5828016   0.51925329  0.56064099  0.59928528\n",
      "  0.52075064  0.59705111  0.59508037  0.58431463  0.59385788  0.63220335\n",
      "  0.52531919  0.59728629  0.59706787  0.59925416  0.42420876  0.58249587\n",
      "  0.59095299  0.50106006  0.63187426  0.57260018  0.59885399  0.51606728\n",
      "  0.563687    0.53004342  0.58092626  0.61403061  0.58238227  0.53994917\n",
      "  0.59658705  0.60761792  0.45244247  0.61815725  0.5317438   0.49393101\n",
      "  0.59952724  0.61251686  0.59928079  0.60150148  0.57654377  0.61575757\n",
      "  0.57427792  0.60040642  0.59812699  0.57466187  0.58010148  0.59791747\n",
      "  0.58742047  0.59994167  0.56350619  0.58496388  0.5818939   0.61140975\n",
      "  0.58022898  0.64550378  0.58626172  0.53612071  0.56804815  0.59555697\n",
      "  0.55645809  0.59214347  0.59049789  0.61538961  0.62179512  0.57362617\n",
      "  0.59007999  0.59071295  0.61493463  0.58963027  0.5943101   0.49697202\n",
      "  0.56170693  0.60285517  0.60521149  0.5905149   0.58099119  0.57945788\n",
      "  0.58578424  0.58522882  0.61302236  0.59194229  0.58916976  0.60133011\n",
      "  0.53191698  0.57808574  0.59027702  0.59352797  0.58168556  0.58194135\n",
      "  0.59857515  0.65823822  0.56229723  0.61680232  0.57325617  0.6592987\n",
      "  0.58325382  0.58554009  0.55460947  0.58042483  0.52092238  0.57735282\n",
      "  0.58413874  0.7211731   0.62019901  0.64633943  0.63741272  0.57351902\n",
      "  0.71024704  0.63212639  0.58609295  0.59212479  0.59090628  0.57439386\n",
      "  0.60022008  0.51553001  0.60762749  0.58176709  0.57016238  0.56993966\n",
      "  0.61981575  0.60112765  0.57511182  0.59389217  0.56729997  0.55630522\n",
      "  0.52095785  0.60322056  0.56692333  0.56777644  0.52209982  0.59824762\n",
      "  0.56300333  0.58528918  0.57955982  0.61188725  0.58680382  0.57899842\n",
      "  0.61141005  0.56881584  0.58546514  0.60712328  0.51357354  0.58927375\n",
      "  0.61355143  0.56255602  0.64468272  0.52518797  0.60123242  0.58341956\n",
      "  0.59436221  0.56028132  0.63690079  0.58957328  0.58952974  0.58772206\n",
      "  0.59230678  0.59944703  0.60644266  0.59147445  0.59872813  0.55150548\n",
      "  0.59498087  0.53106476  0.56065151  0.58337053  0.57986001  0.62206496\n",
      "  0.60285618  0.48192052  0.63330893  0.59376336  0.58044475  0.60893288\n",
      "  0.58513211  0.54602188  0.62276695  0.62287164  0.58942149  0.58663274\n",
      "  0.57685625  0.59644541  0.58637845  0.5716192   0.58011791  0.60205459\n",
      "  0.59258423  0.58811437  0.5844061   0.58267051  0.59209599  0.50212618\n",
      "  0.55878057  0.5975994   0.59167819  0.58006426  0.60761575  0.59758651\n",
      "  0.60031946  0.59271591  0.59193662  0.57952703  0.58225564  0.63116802\n",
      "  0.59938567  0.56142609  0.59578903  0.62801296  0.66236277  0.57954813\n",
      "  0.59633574  0.57794866  0.54737477  0.5967288   0.52378856  0.62812783\n",
      "  0.60067459  0.5574621   0.54047857  0.5772548   0.64367874  0.58313592\n",
      "  0.51383279  0.59112072  0.58327697  0.61710938  0.61475977  0.55970387\n",
      "  0.56244467  0.54631116  0.60082539  0.585088    0.57829623  0.64380396\n",
      "  0.60609538  0.59243994  0.60098983  0.60418469  0.58756304  0.57996879\n",
      "  0.52388251  0.58953791  0.59092992  0.55113555  0.62127362  0.58445765\n",
      "  0.58270745  0.61528888  0.60249871  0.57925806  0.59163129  0.56952562\n",
      "  0.57023099  0.57608941  0.57997375  0.57941128  0.59505166  0.58472187\n",
      "  0.6130967   0.63245578  0.59002728  0.66447652  0.56674709  0.57424885\n",
      "  0.59058676  0.58683784  0.58221175  0.59977434]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4714285714285714]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datos import Datos\n",
    "from estrategiasparticionado.validacion_cruzada import ValidacionCruzada\n",
    "from estrategiasparticionado.validacion_simple import ValidacionSimple\n",
    "from clasificadores.clasificador_regresion_logistica import ClasificadorRegresionLogistica\n",
    "dataset=Datos('./conjunto_datos/example1.data')\n",
    "dataset.datos\n",
    "clasificador = ClasificadorRegresionLogistica()\n",
    "res = clasificador.validacion(validacionSimple, dataset)\n",
    "clasificador.errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clasificador = ClasificadorNaiveBayes()\n",
    "res = clasificador.validacion(validacionSimple, dataset)\n",
    "clasificador.errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dani/Documents/FAA/clasificadores/clasificador_regresion_logistica.py:39: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-prod_escalar))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,) (31,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-fdc7ea1f39a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mii\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestrategia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticiones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindicesTrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m plotModel(dataset.datos[ii,0],dataset.datos[ii,1],dataset.datos\n\u001b[0;32m---> 15\u001b[0;31m [ii,-1]!=0,clasificador,\"Frontera\",dataset.diccionarios)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mclasificador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FAA/plotModel.py\u001b[0m in \u001b[0;36mplotModel\u001b[0;34m(x, y, clase, clf, title, diccionarios)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClasificador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClasificador\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasifica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiccionarios\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"decision_function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FAA/clasificadores/clasificador_regresion_logistica.py\u001b[0m in \u001b[0;36mclasifica\u001b[0;34m(self, datostest, atributosDiscretos, diccionario)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Para cada registro del dataset de clasificacion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindice_fila\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfila\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatostest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobabilidades\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindice_fila\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoidal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfila\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediccion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatostest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FAA/clasificadores/clasificador_regresion_logistica.py\u001b[0m in \u001b[0;36msigmoidal\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msigmoidal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mx_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mprod_escalar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_real\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprod_escalar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (31,) "
     ]
    }
   ],
   "source": [
    "from plotModel import plotModel\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "dataset=Datos('./conjunto_datos/example4.data')\n",
    "dataset.datos\n",
    "clasificador = ClasificadorRegresionLogistica()\n",
    "res = clasificador.validacion(validacionSimple, dataset)\n",
    "\n",
    "estrategia = ValidacionSimple()\n",
    "estrategia.creaParticiones(dataset.datos)\n",
    "ii = estrategia.particiones[-1].indicesTrain\n",
    "plotModel(dataset.datos[ii,0],dataset.datos[ii,1],dataset.datos\n",
    "[ii,-1]!=0,clasificador,\"Frontera\",dataset.diccionarios)\n",
    "clasificador.errores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
