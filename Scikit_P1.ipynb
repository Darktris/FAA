{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datos import Datos\n",
    "from estrategiasparticionado.validacion_cruzada import ValidacionCruzada\n",
    "from estrategiasparticionado.validacion_simple import ValidacionSimple\n",
    "from clasificadores.clasificador_naive_bayes import ClasificadorNaiveBayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools \n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cargar datasets\n",
    "dataset = dataset=Datos('./conjunto_datos/tic-tac-toe.data')\n",
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "Y = dataset.datos[:,-1] \n",
    "class_names = sorted(dataset.diccionarios[-1].keys())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clasificador\n",
    "laplace_smoothing = 0\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validacion cruzada\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=1)\n",
    "scores = cross_val_score(model, X, Y, cv=cv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Entrenamiento para el caso de validacion simple\n",
    "model.fit(X_train, Y_train)\n",
    "score = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: %0.2f\" % (score))\n",
    "cnf_matrix = confusion_matrix(Y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mostrar matrices de confusion\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[[-3. -3. -3. ..., -2. -2. -2.]\n",
      " [-3. -3. -3. ..., -3. -2. -2.]\n",
      " [-3. -3. -3. ..., -2. -3. -2.]\n",
      " ..., \n",
      " [-2. -3. -2. ..., -2. -3. -1.]\n",
      " [-2. -3. -2. ..., -2. -3. -1.]\n",
      " [-2. -2. -3. ..., -3. -3. -1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2791044776119403]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import clasificadores.clasificador_naive_bayes as nb\n",
    "import estrategiasparticionado.validacion_cruzada as vc\n",
    "import estrategiasparticionado.validacion_simple as vs\n",
    "from datos import Datos\n",
    "\n",
    "dataset = Datos('./conjunto_datos/tic-tac-toe.data')\n",
    "\n",
    "#dataset.datos = dataset.datos[::10,-3:]\n",
    "#dataset.diccionarios = dataset.diccionarios[-3:]\n",
    "#dataset.nombreAtributos = dataset.nombreAtributos[-3:]\n",
    "#dataset.tipoAtributos = dataset.tipoAtributos[-3:]\n",
    "#dataset.nominalAtributos = dataset.nominalAtributos[-3:]\n",
    "\n",
    "print(dataset.datos)\n",
    "\n",
    "clasificador = nb.ClasificadorNaiveBayes()\n",
    "estrategia_vc = vc.ValidacionCruzada()\n",
    "estrategia_vs = vs.ValidacionSimple()\n",
    "\n",
    "estrategia_vs.creaParticiones(dataset.datos)\n",
    "\n",
    "res_1 = clasificador.validacion(estrategia_vs, dataset)\n",
    "clasificador.errores\n",
    "#res_2 = clasificador.validacion(estrategia_vc, dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
